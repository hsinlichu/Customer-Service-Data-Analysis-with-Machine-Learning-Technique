{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d40aadd17ed4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"..\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"./newdata_clean.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmax_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m  \u001b[0;31m# only consider the top max_features ordered by term frequency across the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "path = os.path.join(\"..\",\"data\",\"./newdata_clean.xlsx\")\n",
    "n_cpu = 15\n",
    "batch_size = 10000\n",
    "max_k = 40\n",
    "max_features = 256  # only consider the top max_features ordered by term frequency across the corpus.\n",
    "loadpath = \"processed_data_lda_wo_html\"\n",
    "#loadpath = \"processed_data_not_rmsw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(loadpath, \"rb\") as f:\n",
    "    output = pickle.load(f)\n",
    "clean_data = output[\"clean_data\"]\n",
    "reduced_data = output[\"reduced_data\"]\n",
    "token_data = output[\"token_data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Topic Model\n",
    "如果不移除 stopword 的話效果很差，主題的字都會是 of, for, it...\n",
    "`dictionary.filter_extremes()` 過濾掉 token 出現次數少於15個句子，或是出現在超過一半的句子中。 \n",
    "ref: [Topic Modeling and Latent Dirichlet Allocation (LDA) in Python](https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import LdaMulticore\n",
    "import pprint\n",
    "print(\"Data length: {}\".format(len(token_data)))\n",
    "dictionary = gensim.corpora.Dictionary(token_data)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in token_data]\n",
    "print(bow_corpus[4310]) # just print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA using BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=n_cpu)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "print(corpus_tfidf[4310])\n",
    "\n",
    "model_list = []\n",
    "perplexity = []\n",
    "coherence = []\n",
    "\n",
    "n_topic = 80\n",
    "test = [n_topic]\n",
    "for i in test:\n",
    "    print(i)\n",
    "    lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=i, iterations=100000, id2word=dictionary, passes=2, workers=n_cpu)\n",
    "    model_list.append(lda_model_tfidf)\n",
    "    \n",
    "    for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "        print('Topic: {} \\nWord: {}'.format(idx, topic))\n",
    "    print(\"=========================================================================================\")\n",
    "    \n",
    "    # Compute Perplexity\n",
    "    per_score = lda_model_tfidf.log_perplexity(corpus_tfidf)\n",
    "    print('Perplexity: ', per_score)  # a measure of how good the model is. lower the better.\n",
    "    perplexity.append(per_score)\n",
    "\n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model_tfidf, texts=token_data, dictionary=dictionary, coherence='c_v', processes=n_cpu)\n",
    "    coherence_lda = coherence_model_lda.get_coherence() # high is better\n",
    "    print('Coherence Score: ', coherence_lda)\n",
    "    coherence.append(coherence_lda)\n",
    "'''\n",
    "with open(\"perplexity\", \"wb\") as f:\n",
    "    pickle.dump(perplexity, f)\n",
    "with open(\"coherence\", \"wb\") as f:\n",
    "    pickle.dump(coherence, f)\n",
    "with open(\"model_list\", \"wb\") as f:\n",
    "    pickle.dump(model_list, f)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "x = range(1,500)\n",
    "ax[0].plot(x,perplexity)   # , c=label_subset_color\n",
    "ax[0].set_title('BOW Topic Distribution')\n",
    "ax[1].plot(coherence)   # , c=label_subset_color\n",
    "ax[1].set_title('coherence')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topic_example(reduced_data, token_data, model, dictionary, n_topic):\n",
    "    total_len = len(reduced_data)\n",
    "    print(\"total_len\",total_len)\n",
    "\n",
    "    topic_distribution = [0 for i in range(n_topic)]\n",
    "    topic_result = []\n",
    "    example = [[] for i in range(n_topic)]\n",
    "    for s, token in tqdm(zip(reduced_data, token_data), total=total_len):\n",
    "        bow_vector = dictionary.doc2bow(token)\n",
    "        rank = model[bow_vector]\n",
    "        if len(rank) == 0:\n",
    "            continue\n",
    "        index, score = max(rank, key=lambda tup: tup[1])\n",
    "        #print(index,score)\n",
    "        topic_distribution[index] += 1\n",
    "        topic_result.append(index)\n",
    "        example[index].append((s, score))\n",
    "        #print(s)\n",
    "        #print(\"Score: {}  Topic: {}\\n\".format(score, model.print_topic(index, 5)))\n",
    "    print(\"topic_distribution: {}\".format(topic_distribution))\n",
    "    \n",
    "    for idx, topic in model.print_topics(-1):\n",
    "        print('Topic: {} | {} datas\\nWord: {}'.format(idx, topic_distribution[idx], topic))\n",
    "        result = sorted(example[idx], key=lambda tup: -tup[1])[:5]\n",
    "        for s, score in result:\n",
    "            print(\"{} | {}\\n\".format(s,score))\n",
    "        print()\n",
    "        print(\"====================\")\n",
    "    \n",
    "    return topic_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_topic_result = print_topic_example(reduced_data, token_data, lda_model, dictionary, n_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = model_list[0]\n",
    "print(lda_model_tfidf)\n",
    "tfidf_topic_result = print_topic_example(reduced_data, token_data, lda_model_tfidf, dictionary, n_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "visual = pyLDAvis.gensim.prepare(lda_model_tfidf, corpus_tfidf, dictionary)\n",
    "pyLDAvis.display(visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].hist(bow_topic_result, rwidth=0.8)   # , c=label_subset_color\n",
    "ax[0].set_title('BOW Topic Distribution')\n",
    "ax[1].hist(tfidf_topic_result, rwidth=0.8)   # , c=label_subset_color\n",
    "ax[1].set_title('TFIDF Topic Distribution')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
